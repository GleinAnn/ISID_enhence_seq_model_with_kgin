{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "from recbole.data.utils import data_preparation\n",
    "from recbole.model.sequential_recommender.fearec import FEARec\n",
    "from recbole.model.knowledge_aware_recommender.kgin import KGIN\n",
    "from recbole.model.sequential_recommender.bert4rec import BERT4Rec\n",
    "from recbole.model.sequential_recommender.sasrec import SASRec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils.enum_type import KGDataLoaderState\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.quick_start import load_data_and_model\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def recall_at_k(preds, targets, k=10):\n",
    "    recall = []\n",
    "    for pred, target in zip(preds, targets):\n",
    "        recall.append(1.0 if target in pred[:k] else 0.0)\n",
    "    return sum(recall) / len(recall)\n",
    "\n",
    "def ndcg_at_k_ls(pred_ranking, target_item, k=10):\n",
    "    \"\"\"\n",
    "    pred_ranking: list[int] các item theo thứ tự giảm dần điểm\n",
    "    target_item : int, ground-truth item (LS)\n",
    "    k           : cắt top-k\n",
    "    \"\"\"\n",
    "    topk = pred_ranking[:k]\n",
    "    if target_item in topk:\n",
    "        rank = topk.index(target_item) + 1  # 1-based\n",
    "        return 1.0 / math.log2(rank + 1)    # IDCG = 1 với 1 relevant\n",
    "    return 0.0\n",
    "\n",
    "def mean_ndcg_at_k_ls(all_preds, all_targets, k=10):\n",
    "    \"\"\"\n",
    "    all_preds  : List[List[int]]\n",
    "    all_targets: List[int]\n",
    "    \"\"\"\n",
    "    s = 0.0\n",
    "    n = len(all_targets)\n",
    "    for pred, tgt in zip(all_preds, all_targets):\n",
    "        s += ndcg_at_k_ls(pred, tgt, k)\n",
    "    return s / n if n > 0 else 0.0\n",
    "\n",
    "\n",
    "def mrr_at_k(preds, targets, k=10):\n",
    "    reciprocal_ranks = []\n",
    "    for pred, target in zip(preds, targets):\n",
    "        if target in pred[:k]:\n",
    "            rank = pred.index(target) + 1  # 1-based\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0)\n",
    "    return sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "\n",
    "def precision_at_k(preds, targets, k=10):\n",
    "    precision = []\n",
    "    for pred, target in zip(preds, targets):\n",
    "        precision.append(1.0 / k if target in pred[:k] else 0.0)\n",
    "    return sum(precision) / len(precision)\n",
    "\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8be604",
   "metadata": {},
   "source": [
    "# MovieLens_1m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132b122",
   "metadata": {},
   "source": [
    "## SASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11910d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sasrec_params = {\n",
    "    'dataset': 'ml-1m',\n",
    "    'data_path': '/content/drive/MyDrive/Recbole_data/',\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list',\n",
    "    'MAX_ITEM_LIST_LENGTH': 100,\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'filter_inter_by_user_or_item': True,\n",
    "    'user_inter_num_interval': \"[10,inf]\",\n",
    "    'normalize_all': False,\n",
    "    'repeatable': True,\n",
    "\n",
    "    # ==== Model ====\n",
    "    'hidden_size': 64,\n",
    "    'n_layers': 2,\n",
    "    'n_heads': 2,\n",
    "    'inner_size': 256,\n",
    "    'dropout_prob': 0.1,\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'attn_dropout_prob': 0.1,\n",
    "    'hidden_act': 'gelu',\n",
    "    'layer_norm_eps': 1e-12,\n",
    "    'initializer_range': 0.02,\n",
    "\n",
    "    'loss_type': 'CE',\n",
    "    'train_neg_sample_args': None,\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 512,\n",
    "    'eval_batch_size': 1024,\n",
    "    'learner': 'adam',\n",
    "    'learning_rate': 0.0005,\n",
    "    'eval_step': 2,\n",
    "    'stopping_step': 10,\n",
    "\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'],\n",
    "    'topk': [10],\n",
    "    'valid_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "\n",
    "    'seed': 2020,\n",
    "    'device': 'cuda',\n",
    "    'reproducibility': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c55d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sasrec_config = Config(model='SASRec', dataset='ml-1m', config_dict=sasrec_params)\n",
    "sasrec_dataset = create_dataset(sasrec_config)\n",
    "sasrec_train_data, sasrec_valid_data, sasrec_test_data = data_preparation(sasrec_config, sasrec_dataset)\n",
    "sasrec_device = sasrec_config['device']\n",
    "sasrec_model = SASRec(sasrec_config, sasrec_dataset).to(sasrec_device)\n",
    "sasrec_model.load_state_dict(torch.load('SASRec_ML1M_ls.pth'))\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    sasrec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in sasrec_test_data:\n",
    "        scores = sasrec_model.full_sort_predict(batch[0].to(sasrec_device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d143b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgin_params = {\n",
    "    'data_path': '/content/drive/MyDrive/Recbole_data/',\n",
    "    'seed': 2020,\n",
    "    'reproducibility': True,\n",
    "\n",
    "    'device': 'cuda',\n",
    "\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 512,\n",
    "    'eval_batch_size': 1024,\n",
    "    'learning_rate': 0.001,\n",
    "    'embedding_size': 64,\n",
    "    'loss_type': 'BPR',\n",
    "    'train_neg_sample_args': {\n",
    "        'sample_num': 1,\n",
    "        'strategy': 'uniform'\n",
    "    },\n",
    "\n",
    "    'stopping_step': 10,\n",
    "    'eval_step': 2,\n",
    "    'validation_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'order': 'TO',\n",
    "        'group_by': 'user',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "    'log_wandb': False,\n",
    "\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "    'NEG_PREFIX': 'neg_',\n",
    "\n",
    "    'HEAD_ENTITY_ID_FIELD': 'head_id',\n",
    "    'TAIL_ENTITY_ID_FIELD': 'tail_id',\n",
    "    'RELATION_ID_FIELD': 'relation_id',\n",
    "    'ENTITY_ID_FIELD': 'entity_id',\n",
    "\n",
    "    'alias_of_user_id': ['user_id'],\n",
    "    'alias_of_item_id': ['item_id'],\n",
    "    'alias_of_entity_id': ['head_id', 'tail_id'],\n",
    "    'alias_of_relation_id': ['relation_id'],\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp'],\n",
    "        'kg': ['head_id', 'relation_id', 'tail_id'],\n",
    "        'link': ['item_id', 'entity_id']\n",
    "    },\n",
    "\n",
    "    'filter_inter_by_user_or_item': True,\n",
    "    'normalize_all': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce967e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_config = Config(model='KGIN', dataset='ml-1m', config_dict=kgin_params)\n",
    "kg_dataset = create_dataset(kg_config)\n",
    "kg_train_data, kg_valid_data, kg_test_data = data_preparation(kg_config, kg_dataset)\n",
    "kg_device = kg_config['device']\n",
    "kg_model = KGIN(kg_config, kg_dataset).to(kg_device)\n",
    "kg_model.load_state_dict(torch.load('KGIN_ML1M_ls.pth'))\n",
    "\n",
    "# Ma trận điểm kg_model đã padding\n",
    "\n",
    "user_ids = kg_train_data._dataset['user_id'].tolist()\n",
    "item_ids = kg_train_data._dataset['item_id'].tolist()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "user_seen_items = defaultdict(set)\n",
    "\n",
    "for u, i in zip(user_ids, item_ids):\n",
    "    user_seen_items[u].add(i)\n",
    "\n",
    "# compute KG-based scores\n",
    "kgin_ml1m_scores = []\n",
    "\n",
    "for user_id in range(kg_dataset.user_num):\n",
    "    user_ids = [user_id] * kg_dataset.item_num\n",
    "    item_ids = list(range(kg_dataset.item_num))\n",
    "\n",
    "    interaction = Interaction({\n",
    "        'user_id': torch.LongTensor(user_ids),\n",
    "        'item_id': torch.LongTensor(item_ids)\n",
    "    }).to(kg_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = kg_model.predict(interaction).cpu().tolist()\n",
    "\n",
    "    min_score = min(scores)\n",
    "    seen = user_seen_items[user_id]\n",
    "    for j in seen:\n",
    "        # scores[j] = float('-inf')\n",
    "        scores[j] = min_score\n",
    "\n",
    "    kgin_ml1m_scores.append(scores)\n",
    "\n",
    "# compute KG-based scores mapping seq dataset\n",
    "kgin_ml1m_scores_for_seq = []\n",
    "for user_id in range(sasrec_dataset.user_num):\n",
    "    scores = []\n",
    "    for item_id in range(sasrec_dataset.item_num):\n",
    "        item_token = sasrec_dataset.id2token('item_id', item_id)\n",
    "        if item_token in kg_dataset.field2token_id['item_id']:\n",
    "            kg_item_id = kg_dataset.token2id('item_id', item_token)\n",
    "            scores.append(kgin_ml1m_scores[user_id][kg_item_id])\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "    kgin_ml1m_scores_for_seq.append(scores)\n",
    "\n",
    "kgin_ml1m_scores_for_seq = torch.tensor(kgin_ml1m_scores_for_seq).to(sasrec_device)\n",
    "\n",
    "# del kg_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6003fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate hybrid scores\n",
    "sasrec_model.eval()\n",
    "\n",
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "    for batch in sasrec_test_data:\n",
    "        scores = sasrec_model.full_sort_predict(batch[0].to(sasrec_device))\n",
    "        scores = softmax_np(scores)\n",
    "        for i, user_id in enumerate(batch[0]['user_id']):\n",
    "            scores[i] = (1.0 - alpha) * scores[i] + alpha * kgin_ml1m_scores_for_seq[user_id]\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=10, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3d1ac",
   "metadata": {},
   "source": [
    "## BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fc93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert4rec_params = {\n",
    "    'dataset': 'ml-1m',\n",
    "    'data_path': '/content/drive/MyDrive/Recbole_data/',\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list',\n",
    "    'MAX_ITEM_LIST_LENGTH': 100,\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'filter_inter_by_user_or_item': True,\n",
    "    'user_inter_num_interval': \"[10,inf]\",\n",
    "    'normalize_all': False,\n",
    "    'repeatable': True,\n",
    "\n",
    "    'hidden_size': 64,\n",
    "    'n_layers': 2,\n",
    "    'n_heads': 2,\n",
    "    'inner_size': 256,\n",
    "    'dropout_prob': 0.1,\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'attn_dropout_prob': 0.1,\n",
    "    'hidden_act': 'gelu',\n",
    "    'mask_ratio': 0.2,\n",
    "    'layer_norm_eps': 1e-12,\n",
    "    'initializer_range': 0.02,\n",
    "\n",
    "    'loss_type': 'CE',\n",
    "    'train_neg_sample_args': None,\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 512,\n",
    "    'eval_batch_size': 1024,\n",
    "    'learner': 'adam',\n",
    "    'learning_rate': 0.0005,\n",
    "    'eval_step': 2,\n",
    "    'stopping_step': 10,\n",
    "\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'],\n",
    "    'topk': [10],\n",
    "    'valid_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "\n",
    "    'seed': 2020,\n",
    "    'device': 'cuda',\n",
    "    'reproducibility': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert4rec_config = Config(model='BERT4Rec', dataset='ml-1m', config_dict=bert4rec_params)\n",
    "bert4rec_dataset = create_dataset(bert4rec_config)\n",
    "bert4rec_train_data, bert4rec_valid_data, bert4rec_test_data = data_preparation(bert4rec_config, bert4rec_dataset)\n",
    "bert4rec_device = bert4rec_config['device']\n",
    "bert4rec_model = BERT4Rec(bert4rec_config, bert4rec_dataset).to(bert4rec_device)\n",
    "bert4rec_model.load_state_dict(torch.load('BERT4Rec_ML1M_ls.pth'))\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    bert4rec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in bert4rec_test_data:\n",
    "        scores = bert4rec_model.full_sort_predict(batch[0].to(bert4rec_device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate hybrid scores\n",
    "bert4rec_model.eval()\n",
    "\n",
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "    for batch in bert4rec_test_data:\n",
    "        scores = bert4rec_model.full_sort_predict(batch[0].to(bert4rec_device))\n",
    "        scores = softmax_np(scores)\n",
    "        for i, user_id in enumerate(batch[0]['user_id']):\n",
    "            scores[i] = (1.0 - alpha) * scores[i] + alpha * kgin_ml1m_scores_for_seq[user_id]\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=10, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ba51c",
   "metadata": {},
   "source": [
    "## FEARec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fearec_params = {\n",
    "    'data_path': '/content/drive/MyDrive/Recbole_data/',\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "    'NEG_PREFIX': 'neg_',\n",
    "\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list',\n",
    "    'MAX_ITEM_LIST_LENGTH': 50,\n",
    "\n",
    "    'alias_of_user_id': ['user_id'],\n",
    "    'alias_of_item_id': ['item_id'],\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'filter_inter_by_user_or_item': True,\n",
    "    'user_inter_num_interval': \"[10,inf]\",\n",
    "    'normalize_all': False,\n",
    "    'repeatable': True,\n",
    "\n",
    "    'device': 'cuda',\n",
    "    'seed': 2020,\n",
    "    'reproducibility': True,\n",
    "\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 256,\n",
    "    'eval_batch_size': 512,\n",
    "    'learning_rate': 0.001,\n",
    "    'loss_type': 'CE',\n",
    "    'train_neg_sample_args': None,\n",
    "    'stopping_step': 10,\n",
    "    'eval_step': 1,\n",
    "    'validation_metric': 'Recall@10',\n",
    "\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "    'log_wandb': False,\n",
    "\n",
    "    'embedding_size': 64,\n",
    "    'hidden_size': 64,\n",
    "    'n_heads': 2,\n",
    "    'num_layers': 2,\n",
    "    'dropout_prob': 0.1,\n",
    "\n",
    "    'use_ssl': True,\n",
    "    'use_supcon': True,\n",
    "    'ssl_temp': 0.2,\n",
    "    'supcon_weight': 0.1,\n",
    "    'ssl_weight': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fearec_config = Config(model='FEARec', dataset='ml-1m', config_dict=fearec_params)\n",
    "fearec_dataset = create_dataset(fearec_config)\n",
    "fearec_train_data, fearec_valid_data, fearec_test_data = data_preparation(fearec_config, fearec_dataset)\n",
    "fearec_device = fearec_config['device']\n",
    "fearec_model = FEARec(fearec_config, fearec_dataset).to(fearec_device)\n",
    "fearec_model.load_state_dict(torch.load('FEARec_ML1M_ls.pth'))\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    fearec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in fearec_test_data:\n",
    "        scores = fearec_model.full_sort_predict(batch[0].to(fearec_device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate hybrid scores\n",
    "fearec_model.eval()\n",
    "\n",
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "    for batch in fearec_test_data:\n",
    "        scores = fearec_model.full_sort_predict(batch[0].to(fearec_device))\n",
    "        scores = softmax_np(scores)\n",
    "        for i, user_id in enumerate(batch[0]['user_id']):\n",
    "            scores[i] = (1.0 - alpha) * scores[i] + alpha * kgin_ml1m_scores_for_seq[user_id]\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=10, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16b70f",
   "metadata": {},
   "source": [
    "# Amazon_Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c75f3",
   "metadata": {},
   "source": [
    "## SASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389235ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sasrec_config = {\n",
    "    'data_path': 'D:\\Personal\\RecBole',\n",
    "    'seed': 2020,\n",
    "    'reproducibility': True,\n",
    "    'device': 'cuda',\n",
    "\n",
    "    # Training\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 256,\n",
    "    'eval_batch_size': 512,\n",
    "    'learning_rate': 0.001,\n",
    "    'loss_type': 'CE',\n",
    "    'train_neg_sample_args': None,  # Bắt buộc với CE\n",
    "\n",
    "    # Evaluation\n",
    "    'eval_step': 2,\n",
    "    'stopping_step': 5,\n",
    "    'validation_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "\n",
    "    'log_wandb': False,\n",
    "    'save_checkpoint': True,\n",
    "\n",
    "    # Data fields\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "    'NEG_PREFIX': 'neg_',\n",
    "\n",
    "    'alias_of_user_id': ['user_id'],\n",
    "    'alias_of_item_id': ['item_id'],\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "\n",
    "    # Sequence-specific\n",
    "    'normalize_all': False,\n",
    "    'MAX_ITEM_LIST_LENGTH': 40,\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='SASRec', dataset='Amazon_Books_filtered', config_dict=sasrec_config)\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "device = config['device']\n",
    "model = SASRec(config, dataset).to(device)\n",
    "\n",
    "trainer = Trainer(config, model)\n",
    "print(\"[DEBUG] Bắt đầu huấn luyện\")\n",
    "trainer.fit(train_data, valid_data)\n",
    "res = trainer.evaluate(test_data)\n",
    "print(res)\n",
    "torch.save(model.state_dict(), 'SASRec_AB_filtered_ls.pth')\n",
    "\n",
    "del model\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd806449",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgin_config = {\n",
    "    'data_path': 'D:\\Personal\\RecBole',\n",
    "    'seed': 2020,\n",
    "    'reproducibility': True,\n",
    "\n",
    "    'device': 'cuda',\n",
    "\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 256,\n",
    "    'eval_batch_size': 512,\n",
    "    'learning_rate': 0.001,\n",
    "    'embedding_size': 64,\n",
    "    'loss_type': 'BPR',\n",
    "    'train_neg_sample_args': {\n",
    "        'sample_num': 1,\n",
    "        'strategy': 'uniform'\n",
    "    },\n",
    "\n",
    "    'stopping_step': 5,\n",
    "    'eval_step': 1,\n",
    "    'validation_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "    'log_wandb': False,\n",
    "\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "    'NEG_PREFIX': 'neg_',\n",
    "\n",
    "    'HEAD_ENTITY_ID_FIELD': 'head_id',\n",
    "    'TAIL_ENTITY_ID_FIELD': 'tail_id',\n",
    "    'RELATION_ID_FIELD': 'relation_id',\n",
    "    'ENTITY_ID_FIELD': 'entity_id',\n",
    "\n",
    "    'alias_of_user_id': ['user_id'],\n",
    "    'alias_of_item_id': ['item_id'],\n",
    "    'alias_of_entity_id': ['head_id', 'tail_id'],\n",
    "    'alias_of_relation_id': ['relation_id'],\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp'],\n",
    "        'kg': ['head_id', 'relation_id', 'tail_id'],\n",
    "        'link': ['item_id', 'entity_id']\n",
    "    },\n",
    "    'normalize_all': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86314d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_config = Config(model='KGIN', dataset='Amazon_Books_filtered', config_dict=kgin_config)\n",
    "kg_dataset = create_dataset(kg_config)\n",
    "kg_train_data, kg_valid_data, kg_test_data = data_preparation(kg_config, kg_dataset)\n",
    "kg_device = kg_config['device']\n",
    "kg_model = KGIN(kg_config, kg_dataset).to(kg_device)\n",
    "\n",
    "\n",
    "kg_trainer = Trainer(kg_config, kg_model)\n",
    "kg_train_data.set_mode(KGDataLoaderState.RS)\n",
    "kg_trainer.fit(kg_train_data, kg_valid_data)\n",
    "kg_res = kg_trainer.evaluate(kg_test_data)\n",
    "print(kg_res)\n",
    "torch.save(kg_model.state_dict(), 'KGIN_AB_filtered_ls.pth')\n",
    "\n",
    "del kg_model\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00332e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sasrec_config = Config(model='SASRec', dataset='Amazon_Books_filtered', config_dict=sasrec_config)\n",
    "sasrec_dataset = create_dataset(sasrec_config)\n",
    "sasrec_train_data, sasrec_valid_data, sasrec_test_data = data_preparation(sasrec_config, sasrec_dataset)\n",
    "sasrec_device = sasrec_config['device']\n",
    "sasrec_model = SASRec(sasrec_config, sasrec_dataset).to(sasrec_device)\n",
    "sasrec_model.load_state_dict(torch.load('SASRec_AB_filtered_ls.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f42500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    sasrec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in sasrec_test_data:\n",
    "        scores = sasrec_model.full_sort_predict(batch[0].to(sasrec_device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_config = Config(model='KGIN', dataset='Amazon_Books_filtered', config_dict=kgin_config)\n",
    "kg_dataset = create_dataset(kg_config)\n",
    "kg_train_data, kg_valid_data, kg_test_data = data_preparation(kg_config, kg_dataset)\n",
    "kg_device = kg_config['device']\n",
    "kg_model = KGIN(kg_config, kg_dataset).to(kg_device)\n",
    "kg_model.load_state_dict(torch.load('KGIN_AB_filtered_ls.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230701b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "def build_kg_matrix_in_ram(\n",
    "    sasrec_dataset, sasrec_test_data,\n",
    "    kg_dataset, kg_model,\n",
    "    dtype=np.float32,           # đổi sang np.float16 nếu cần tiết kiệm RAM\n",
    "    show_progress=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Trả về:\n",
    "      - kg_matrix: np.ndarray shape [num_rows, n_items_seq], dtype=dtype\n",
    "      - row_uid_tokens: list[str] thứ tự user_token tương ứng từng hàng\n",
    "      - seq_pos: np.ndarray[int64] các cột SEQ có tương ứng trong KG\n",
    "      - kg_ids : np.ndarray[int64] id item tương ứng bên KG (cùng chiều với seq_pos)\n",
    "    \"\"\"\n",
    "\n",
    "    kg_model.eval()\n",
    "    kg_device = next(kg_model.parameters()).device\n",
    "\n",
    "    # === Không gian item SEQ và map sang KG ===\n",
    "    n_items_seq = sasrec_dataset.item_num\n",
    "    seq_tokens = [sasrec_dataset.id2token('item_id', i) for i in range(n_items_seq)]\n",
    "    kg_tok2id_item = kg_dataset.field2token_id['item_id']  # token->id (KG)\n",
    "    kg_idx_for_seq = np.array([kg_tok2id_item.get(t, -1) for t in seq_tokens], dtype=np.int64)\n",
    "\n",
    "    # Giới hạn theo kích thước embedding hiện có của KG (an toàn CUDA)\n",
    "    ue = getattr(kg_model, \"user_embedding\", None) or getattr(kg_model, \"entity_embedding\", None)\n",
    "    ie = getattr(kg_model, \"item_embedding\", None) or getattr(kg_model, \"relation_embedding\", None)\n",
    "    MAX_U = None if ue is None else ue.num_embeddings\n",
    "    MAX_I = None if ie is None else ie.num_embeddings\n",
    "\n",
    "    valid_mask = kg_idx_for_seq >= 0\n",
    "    if MAX_I is not None:\n",
    "        valid_mask &= (kg_idx_for_seq < MAX_I)\n",
    "\n",
    "    seq_pos = np.flatnonzero(valid_mask)     # cột trong SEQ có tương ứng ở KG\n",
    "    kg_ids  = kg_idx_for_seq[seq_pos]        # item_id tương ứng bên KG\n",
    "\n",
    "    if len(seq_pos) == 0:\n",
    "        raise RuntimeError(\"Không có item chung hợp lệ giữa SEQ và KG (seq_pos rỗng).\")\n",
    "\n",
    "    # ====== Duyệt test loader & ghép thành ma trận trong RAM ======\n",
    "    rows = []\n",
    "    row_uid_tokens = []\n",
    "\n",
    "    it = tqdm(sasrec_test_data, desc=\"KG → RAM (per-row)\", disable=not show_progress)\n",
    "    with torch.no_grad():\n",
    "        for batch in it:\n",
    "            inp = batch[0]\n",
    "            user_ids   = inp['user_id'].cpu().tolist()\n",
    "            item_lists = inp['item_id_list'].cpu().tolist()   # index theo SEQ\n",
    "\n",
    "            for i, uid in enumerate(user_ids):\n",
    "                # Hàng kết quả (không gian SEQ), mặc định 0.0 cho item không có trong KG\n",
    "                row = np.zeros(n_items_seq, dtype=dtype)\n",
    "\n",
    "                uid_tok = sasrec_dataset.id2token('user_id', uid)\n",
    "                row_uid_tokens.append(uid_tok)\n",
    "\n",
    "                # Tính điểm KG chỉ trên item chung\n",
    "                sub = None\n",
    "                if (uid_tok in kg_dataset.field2token_id['user_id']) and (len(seq_pos) > 0):\n",
    "                    kg_uid = kg_dataset.token2id('user_id', uid_tok)\n",
    "                    if (MAX_U is None) or (kg_uid < MAX_U):\n",
    "                        inter = Interaction({\n",
    "                            'user_id': torch.full((len(kg_ids),), kg_uid, dtype=torch.long),\n",
    "                            'item_id': torch.as_tensor(kg_ids, dtype=torch.long),\n",
    "                        }).to(kg_device)\n",
    "\n",
    "                        try:\n",
    "                            out = kg_model.predict(inter)\n",
    "                        except AttributeError:\n",
    "                            out = kg_model.forward(inter)\n",
    "\n",
    "                        sub = out.detach().cpu().numpy().reshape(-1).astype(dtype)  # len == len(kg_ids)\n",
    "                        row[seq_pos] = sub\n",
    "\n",
    "                # Gán min-score cho item đã tương tác (index theo SEQ), loại pad=0 nếu có\n",
    "                if sub is not None and sub.size > 0:\n",
    "                    min_score = dtype(sub.min())\n",
    "                else:\n",
    "                    min_score = dtype(0.0)\n",
    "\n",
    "                seen_idx = np.fromiter((x for x in set(item_lists[i]) if 0 < x < n_items_seq), dtype=np.int64)\n",
    "                if seen_idx.size > 0:\n",
    "                    row[seen_idx] = min_score\n",
    "\n",
    "                rows.append(row)\n",
    "\n",
    "    # Ghép tất cả hàng thành 1 ma trận trong RAM\n",
    "    kg_matrix = np.stack(rows, axis=0)\n",
    "    return kg_matrix, row_uid_tokens, seq_pos, kg_ids\n",
    "\n",
    "# ==== Ví dụ gọi hàm (giữ trong RAM) ====\n",
    "# CẢNH BÁO RAM: cân nhắc đổi dtype=np.float16 nếu n_items_seq lớn\n",
    "kg_matrix, row_uid_tokens, SEQ_POS, KG_IDS = build_kg_matrix_in_ram(\n",
    "    sasrec_dataset, sasrec_test_data,\n",
    "    kg_dataset, kg_model,\n",
    "    dtype=np.float32,     # đổi np.float16 nếu thiếu RAM\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(\"[INFO] KG matrix in RAM:\", kg_matrix.shape, kg_matrix.dtype)\n",
    "print(\"[INFO] Rows (users/sequences):\", len(row_uid_tokens))\n",
    "print(\"[INFO] Common items:\", len(SEQ_POS), \" / SEQ items:\", sasrec_dataset.item_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, math\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "# ---------- Softmax normalize ----------\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n",
    "\n",
    "# ---------- Cấu hình ----------\n",
    "assert 'kg_matrix' in globals(), \"Thiếu biến kg_matrix (điểm KG trong RAM).\"\n",
    "sasrec_model.eval()\n",
    "device = sasrec_device\n",
    "\n",
    "# K và alpha bạn đang dùng\n",
    "K_list  = [10]\n",
    "alphas  = [round(a, 1) for a in np.arange(0.0, 1.0, 0.1)]\n",
    "maxK = max(K_list)\n",
    "\n",
    "# Hình dạng ma trận KG (phải khớp số cột với không gian item của SEQ)\n",
    "num_rows, n_items_seq = kg_matrix.shape\n",
    "if kg_matrix.dtype != np.float32:\n",
    "    kg_matrix = kg_matrix.astype(np.float32, copy=False)  # đảm bảo float32 (nhanh & gọn)\n",
    "\n",
    "# ---------- Bộ đếm metric (LS) ----------\n",
    "total = 0\n",
    "metrics = {a: {k: {\"hits\": 0, \"mrr\": 0.0, \"ndcg\": 0.0} for k in K_list} for a in alphas}\n",
    "row_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sasrec_test_data, desc=\"Fusion (RAM) + Evaluate\"):\n",
    "        # --- Ground truth (LS) an toàn ---\n",
    "        b1 = batch[1] if len(batch) > 1 else None\n",
    "        if (b1 is not None) and ('item_id' in b1):\n",
    "            gts = b1['item_id'].cpu().tolist()\n",
    "        elif 'item_id' in batch[0]:\n",
    "            # một số cấu hình để GT ở batch[0]\n",
    "            gts = batch[0]['item_id'].cpu().tolist()\n",
    "        else:\n",
    "            # không tìm thấy GT → bỏ qua batch\n",
    "            continue\n",
    "        bsz = len(gts)\n",
    "\n",
    "        # --- Interaction tối thiểu cho SASRec (tránh field thừa) ---\n",
    "        fields = {\n",
    "            'user_id': batch[0]['user_id'],\n",
    "            'item_id_list': batch[0]['item_id_list']\n",
    "        }\n",
    "        if 'item_length' in batch[0]:\n",
    "            fields['item_length'] = batch[0]['item_length']\n",
    "        inter_seq = Interaction({k: v.clone() for k, v in fields.items()})\n",
    "\n",
    "        # --- Seq scores theo batch (GPU→CPU fallback nếu cần) ---\n",
    "        try:\n",
    "            s_scores = sasrec_model.full_sort_predict(inter_seq.to(device)).detach().cpu().numpy()\n",
    "        except RuntimeError as e:\n",
    "            print(\"[WARN] full_sort_predict(GPU) fail, fallback CPU:\", str(e)[:120])\n",
    "            m_cpu = sasrec_model.to('cpu')\n",
    "            s_scores = m_cpu.full_sort_predict(inter_seq.to('cpu')).detach().cpu().numpy()\n",
    "            sasrec_model.to(device)\n",
    "\n",
    "        # --- Bảo đảm còn đủ hàng KG để so khớp ---\n",
    "        if row_idx + bsz > num_rows:\n",
    "            # cắt cho vừa (tránh out-of-range); in cảnh báo\n",
    "            usable = num_rows - row_idx\n",
    "            if usable <= 0:\n",
    "                break\n",
    "            print(f\"[WARN] Cắt batch cuối: cần {bsz}, chỉ còn {usable} hàng KG.\")\n",
    "            gts = gts[:usable]\n",
    "            s_scores = s_scores[:usable]\n",
    "            bsz = usable\n",
    "\n",
    "        # --- Xử lý từng hàng ---\n",
    "        for b in range(bsz):\n",
    "            s_norm = softmax_np(s_scores[b])\n",
    "            k_norm = softmax_np(kg_matrix[row_idx])\n",
    "            gt = gts[b]\n",
    "            total += 1\n",
    "\n",
    "            for a in alphas:\n",
    "                fused = (1.0 - a) * s_norm + a * k_norm\n",
    "\n",
    "                # Top-maxK (argpartition) rồi sort trong top\n",
    "                idx_part = np.argpartition(-fused, maxK - 1)[:maxK]\n",
    "                idx_sorted = idx_part[np.argsort(-fused[idx_part])]\n",
    "\n",
    "                # vị trí GT trong top-maxK (nếu có)\n",
    "                pos = np.where(idx_sorted == gt)[0]\n",
    "                if pos.size > 0:\n",
    "                    rank1 = int(pos[0]) + 1  # 1-based\n",
    "                    inv_log = 1.0 / math.log2(rank1 + 1)\n",
    "                    inv_rank = 1.0 / rank1\n",
    "                    for K in K_list:\n",
    "                        if rank1 <= K:\n",
    "                            d = metrics[a][K]\n",
    "                            d[\"hits\"] += 1\n",
    "                            d[\"mrr\"]  += inv_rank\n",
    "                            d[\"ndcg\"] += inv_log\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "# ---------- In kết quả ----------\n",
    "print(f\"\\n[INFO] Tổng mẫu đánh giá: {total}  |  Rows đã dùng: {row_idx}/{num_rows}\")\n",
    "for a in alphas:\n",
    "    for K in K_list:\n",
    "        d = metrics[a][K]\n",
    "        hit = d[\"hits\"]; mrr_sum = d[\"mrr\"]; ndcg_sum = d[\"ndcg\"]\n",
    "        recall = hit / total if total else 0.0                 # LS: Hit@K == Recall@K\n",
    "        precision = hit / (total * K) if total else 0.0        # LS precision\n",
    "        mrr = mrr_sum / total if total else 0.0\n",
    "        ndcg = ndcg_sum / total if total else 0.0\n",
    "        print(f\"[alpha={a:.1f} | K={K:>2}] \"\n",
    "              f\"Recall={recall:.5f}  Precision={precision:.5f}  NDCG={ndcg:.5f}  MRR={mrr:.5f}\")\n",
    "\n",
    "if row_idx != num_rows:\n",
    "    print(f\"[WARN] Số hàng KG không khớp: đã dùng {row_idx}, còn dư {num_rows - row_idx}. \"\n",
    "          \"Đảm bảo thứ tự duyệt khi build kg_matrix khớp test_loader.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599328c",
   "metadata": {},
   "source": [
    "## BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert4rec_config = {\n",
    "    'data_path': 'D:\\Personal\\RecBole',\n",
    "    'seed': 2020,\n",
    "    'reproducibility': True,\n",
    "    'device': 'cuda',\n",
    "\n",
    "    # Training\n",
    "    'epochs': 35,\n",
    "    'train_batch_size': 256,\n",
    "    'eval_batch_size': 512,\n",
    "    'learning_rate': 0.001,\n",
    "    'loss_type': 'CE',\n",
    "    'train_neg_sample_args': None,  # Required for CE loss\n",
    "\n",
    "    'eval_step': 2,\n",
    "    'stopping_step': 5,\n",
    "    'validation_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "    'log_wandb': False,\n",
    "\n",
    "    # Data fields\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "    'NEG_PREFIX': 'neg_',\n",
    "\n",
    "    'alias_of_user_id': ['user_id'],\n",
    "    'alias_of_item_id': ['item_id'],\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "\n",
    "    # Filtering\n",
    "    'normalize_all': False,\n",
    "\n",
    "    # Sequence-specific\n",
    "    'mask_ratio': 0.2,\n",
    "    'dropout_prob': 0.2,\n",
    "    'MAX_ITEM_LIST_LENGTH': 40,\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='BERT4Rec', dataset='Amazon_Books_filtered', config_dict=bert4rec_config)\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "device = config['device']\n",
    "model = BERT4Rec(config, dataset).to(device)\n",
    "\n",
    "trainer = Trainer(config, model)\n",
    "print(\"[DEBUG] Bắt đầu huấn luyện\")\n",
    "trainer.fit(train_data, valid_data)\n",
    "res = trainer.evaluate(test_data)\n",
    "print(res)\n",
    "torch.save(model.state_dict(), 'BERT4Rec_AB_filtered_ls.pth')\n",
    "\n",
    "del model\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='BERT4Rec', dataset='Amazon_Books_filtered', config_dict=bert4rec_config)\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "device = config['device']\n",
    "model = BERT4Rec(config, dataset).to(device)\n",
    "model.load_state_dict(torch.load('BERT4Rec_AB_filtered_ls.pth'))\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in test_data:\n",
    "        scores = model.full_sort_predict(batch[0].to(device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a290d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, math\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "# ---------- Softmax normalize ----------\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n",
    "\n",
    "# ---------- Cấu hình ----------\n",
    "assert 'kg_matrix' in globals(), \"Thiếu biến kg_matrix (điểm KG trong RAM).\"\n",
    "model.eval()\n",
    "device = model.device\n",
    "\n",
    "# K và alpha bạn đang dùng\n",
    "K_list  = [10]\n",
    "alphas  = [round(a, 1) for a in np.arange(0.0, 1.0, 0.1)]\n",
    "maxK = max(K_list)\n",
    "\n",
    "# Hình dạng ma trận KG (phải khớp số cột với không gian item của SEQ)\n",
    "num_rows, n_items_seq = kg_matrix.shape\n",
    "if kg_matrix.dtype != np.float32:\n",
    "    kg_matrix = kg_matrix.astype(np.float32, copy=False)  # đảm bảo float32 (nhanh & gọn)\n",
    "\n",
    "# ---------- Bộ đếm metric (LS) ----------\n",
    "total = 0\n",
    "metrics = {a: {k: {\"hits\": 0, \"mrr\": 0.0, \"ndcg\": 0.0} for k in K_list} for a in alphas}\n",
    "row_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sasrec_test_data, desc=\"Fusion (RAM) + Evaluate\"):\n",
    "        # --- Ground truth (LS) an toàn ---\n",
    "        b1 = batch[1] if len(batch) > 1 else None\n",
    "        if (b1 is not None) and ('item_id' in b1):\n",
    "            gts = b1['item_id'].cpu().tolist()\n",
    "        elif 'item_id' in batch[0]:\n",
    "            # một số cấu hình để GT ở batch[0]\n",
    "            gts = batch[0]['item_id'].cpu().tolist()\n",
    "        else:\n",
    "            # không tìm thấy GT → bỏ qua batch\n",
    "            continue\n",
    "        bsz = len(gts)\n",
    "\n",
    "        fields = {\n",
    "            'user_id': batch[0]['user_id'],\n",
    "            'item_id_list': batch[0]['item_id_list']\n",
    "        }\n",
    "        if 'item_length' in batch[0]:\n",
    "            fields['item_length'] = batch[0]['item_length']\n",
    "        inter_seq = Interaction({k: v.clone() for k, v in fields.items()})\n",
    "\n",
    "        # --- Seq scores theo batch (GPU→CPU fallback nếu cần) ---\n",
    "        try:\n",
    "            s_scores = model.full_sort_predict(inter_seq.to(device)).detach().cpu().numpy()\n",
    "        except RuntimeError as e:\n",
    "            print(\"[WARN] full_sort_predict(GPU) fail, fallback CPU:\", str(e)[:120])\n",
    "            m_cpu = model.to('cpu')\n",
    "            s_scores = m_cpu.full_sort_predict(inter_seq.to('cpu')).detach().cpu().numpy()\n",
    "            model.to(device)\n",
    "\n",
    "        # --- Bảo đảm còn đủ hàng KG để so khớp ---\n",
    "        if row_idx + bsz > num_rows:\n",
    "            # cắt cho vừa (tránh out-of-range); in cảnh báo\n",
    "            usable = num_rows - row_idx\n",
    "            if usable <= 0:\n",
    "                break\n",
    "            print(f\"[WARN] Cắt batch cuối: cần {bsz}, chỉ còn {usable} hàng KG.\")\n",
    "            gts = gts[:usable]\n",
    "            s_scores = s_scores[:usable]\n",
    "            bsz = usable\n",
    "\n",
    "        # --- Xử lý từng hàng ---\n",
    "        for b in range(bsz):\n",
    "            s_norm = softmax_np(s_scores[b])\n",
    "            k_norm = softmax_np(kg_matrix[row_idx])\n",
    "            gt = gts[b]\n",
    "            total += 1\n",
    "\n",
    "            for a in alphas:\n",
    "                fused = (1.0 - a) * s_norm + a * k_norm\n",
    "\n",
    "                # Top-maxK (argpartition) rồi sort trong top\n",
    "                idx_part = np.argpartition(-fused, maxK - 1)[:maxK]\n",
    "                idx_sorted = idx_part[np.argsort(-fused[idx_part])]\n",
    "\n",
    "                # vị trí GT trong top-maxK (nếu có)\n",
    "                pos = np.where(idx_sorted == gt)[0]\n",
    "                if pos.size > 0:\n",
    "                    rank1 = int(pos[0]) + 1  # 1-based\n",
    "                    inv_log = 1.0 / math.log2(rank1 + 1)\n",
    "                    inv_rank = 1.0 / rank1\n",
    "                    for K in K_list:\n",
    "                        if rank1 <= K:\n",
    "                            d = metrics[a][K]\n",
    "                            d[\"hits\"] += 1\n",
    "                            d[\"mrr\"]  += inv_rank\n",
    "                            d[\"ndcg\"] += inv_log\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "# ---------- In kết quả ----------\n",
    "print(f\"\\n[INFO] Tổng mẫu đánh giá: {total}  |  Rows đã dùng: {row_idx}/{num_rows}\")\n",
    "for a in alphas:\n",
    "    for K in K_list:\n",
    "        d = metrics[a][K]\n",
    "        hit = d[\"hits\"]; mrr_sum = d[\"mrr\"]; ndcg_sum = d[\"ndcg\"]\n",
    "        recall = hit / total if total else 0.0                 # LS: Hit@K == Recall@K\n",
    "        precision = hit / (total * K) if total else 0.0        # LS precision\n",
    "        mrr = mrr_sum / total if total else 0.0\n",
    "        ndcg = ndcg_sum / total if total else 0.0\n",
    "        print(f\"[alpha={a:.1f} | K={K:>2}] \"\n",
    "              f\"Recall={recall:.5f}  Precision={precision:.5f}  NDCG={ndcg:.5f}  MRR={mrr:.5f}\")\n",
    "\n",
    "if row_idx != num_rows:\n",
    "    print(f\"[WARN] Số hàng KG không khớp: đã dùng {row_idx}, còn dư {num_rows - row_idx}. \"\n",
    "          \"Đảm bảo thứ tự duyệt khi build kg_matrix khớp test_loader.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014106d",
   "metadata": {},
   "source": [
    "## FEARec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd42ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fearec_config = {\n",
    "    'data_path': 'D:\\Personal\\RecBole',\n",
    "    'seed': 2020,\n",
    "    'reproducibility': True,\n",
    "    'device': 'cuda',\n",
    "\n",
    "    'epochs': 35,\n",
    "    'train_batch_size': 256,\n",
    "    'eval_batch_size': 512,\n",
    "    'learning_rate': 1e-3,\n",
    "\n",
    "    'loss_type': 'CE',                     \n",
    "    'train_neg_sample_args': None,        \n",
    "\n",
    "    'eval_step': 2,\n",
    "    'stopping_step': 5,\n",
    "    'validation_metric': 'Recall@10',\n",
    "    'eval_args': {\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'\n",
    "    },\n",
    "    'log_wandb': False,\n",
    "\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'LABEL_FIELD': 'label',\n",
    "    'NEG_PREFIX': 'neg_',\n",
    "    'alias_of_user_id': ['user_id'],\n",
    "    'alias_of_item_id': ['item_id'],\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'normalize_all': False,\n",
    "\n",
    "    'MAX_ITEM_LIST_LENGTH': 40,\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list',\n",
    "\n",
    "    'hidden_size': 64,           \n",
    "    'inner_size': 256,            \n",
    "    'n_layers': 2,\n",
    "    'n_heads': 2,\n",
    "    'hidden_dropout_prob': 0.5,\n",
    "    'attn_dropout_prob': 0.5,\n",
    "    'hidden_act': 'gelu',          \n",
    "    'layer_norm_eps': 1e-12,\n",
    "    'initializer_range': 0.02,\n",
    "\n",
    "    'global_ratio': 1.0,          \n",
    "    'dual_domain': False,          \n",
    "    'std': False,                 \n",
    "    'fredom': False,               \n",
    "    'spatial_ratio': 0.0,          \n",
    "    'topk_factor': 1,              \n",
    "    'lmd': 0.1,                    \n",
    "    'lmd_sem': 0.1,                \n",
    "    'fredom_type': None,           \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='FEARec', dataset='Amazon_Books_filtered', config_dict=fearec_config)\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "device = config['device']\n",
    "model = FEARec(config, dataset).to(device)\n",
    "\n",
    "trainer = Trainer(config, model)\n",
    "print(\"[DEBUG] Bắt đầu huấn luyện\")\n",
    "trainer.fit(train_data, valid_data)\n",
    "res = trainer.evaluate(test_data)\n",
    "print(res)\n",
    "torch.save(model.state_dict(), 'FEARec_AB_filtered_ls.pth')\n",
    "\n",
    "del model\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c13ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='FEARec', dataset='Amazon_Books_filtered', config_dict=fearec_config)\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "device = config['device']\n",
    "model = FEARec(config, dataset).to(device)\n",
    "model.load_state_dict(torch.load('FEARec_AB_filtered_ls.pth'))\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in test_data:\n",
    "        scores = model.full_sort_predict(batch[0].to(device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, math\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "# ---------- Softmax normalize ----------\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n",
    "\n",
    "# ---------- Cấu hình ----------\n",
    "assert 'kg_matrix' in globals(), \"Thiếu biến kg_matrix (điểm KG trong RAM).\"\n",
    "model.eval()\n",
    "device = model.device\n",
    "\n",
    "# K và alpha bạn đang dùng\n",
    "K_list  = [10]\n",
    "alphas  = [round(a, 1) for a in np.arange(0.0, 1.0, 0.1)]\n",
    "maxK = max(K_list)\n",
    "\n",
    "# Hình dạng ma trận KG (phải khớp số cột với không gian item của SEQ)\n",
    "num_rows, n_items_seq = kg_matrix.shape\n",
    "if kg_matrix.dtype != np.float32:\n",
    "    kg_matrix = kg_matrix.astype(np.float32, copy=False)  # đảm bảo float32 (nhanh & gọn)\n",
    "\n",
    "# ---------- Bộ đếm metric (LS) ----------\n",
    "total = 0\n",
    "metrics = {a: {k: {\"hits\": 0, \"mrr\": 0.0, \"ndcg\": 0.0} for k in K_list} for a in alphas}\n",
    "row_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sasrec_test_data, desc=\"Fusion (RAM) + Evaluate\"):\n",
    "        # --- Ground truth (LS) an toàn ---\n",
    "        b1 = batch[1] if len(batch) > 1 else None\n",
    "        if (b1 is not None) and ('item_id' in b1):\n",
    "            gts = b1['item_id'].cpu().tolist()\n",
    "        elif 'item_id' in batch[0]:\n",
    "            # một số cấu hình để GT ở batch[0]\n",
    "            gts = batch[0]['item_id'].cpu().tolist()\n",
    "        else:\n",
    "            # không tìm thấy GT → bỏ qua batch\n",
    "            continue\n",
    "        bsz = len(gts)\n",
    "\n",
    "        fields = {\n",
    "            'user_id': batch[0]['user_id'],\n",
    "            'item_id_list': batch[0]['item_id_list']\n",
    "        }\n",
    "        if 'item_length' in batch[0]:\n",
    "            fields['item_length'] = batch[0]['item_length']\n",
    "        inter_seq = Interaction({k: v.clone() for k, v in fields.items()})\n",
    "\n",
    "        # --- Seq scores theo batch (GPU→CPU fallback nếu cần) ---\n",
    "        try:\n",
    "            s_scores = model.full_sort_predict(inter_seq.to(device)).detach().cpu().numpy()\n",
    "        except RuntimeError as e:\n",
    "            print(\"[WARN] full_sort_predict(GPU) fail, fallback CPU:\", str(e)[:120])\n",
    "            m_cpu = model.to('cpu')\n",
    "            s_scores = m_cpu.full_sort_predict(inter_seq.to('cpu')).detach().cpu().numpy()\n",
    "            model.to(device)\n",
    "\n",
    "        # --- Bảo đảm còn đủ hàng KG để so khớp ---\n",
    "        if row_idx + bsz > num_rows:\n",
    "            # cắt cho vừa (tránh out-of-range); in cảnh báo\n",
    "            usable = num_rows - row_idx\n",
    "            if usable <= 0:\n",
    "                break\n",
    "            print(f\"[WARN] Cắt batch cuối: cần {bsz}, chỉ còn {usable} hàng KG.\")\n",
    "            gts = gts[:usable]\n",
    "            s_scores = s_scores[:usable]\n",
    "            bsz = usable\n",
    "\n",
    "        # --- Xử lý từng hàng ---\n",
    "        for b in range(bsz):\n",
    "            s_norm = softmax_np(s_scores[b])\n",
    "            k_norm = softmax_np(kg_matrix[row_idx])\n",
    "            gt = gts[b]\n",
    "            total += 1\n",
    "\n",
    "            for a in alphas:\n",
    "                fused = (1.0 - a) * s_norm + a * k_norm\n",
    "\n",
    "                # Top-maxK (argpartition) rồi sort trong top\n",
    "                idx_part = np.argpartition(-fused, maxK - 1)[:maxK]\n",
    "                idx_sorted = idx_part[np.argsort(-fused[idx_part])]\n",
    "\n",
    "                # vị trí GT trong top-maxK (nếu có)\n",
    "                pos = np.where(idx_sorted == gt)[0]\n",
    "                if pos.size > 0:\n",
    "                    rank1 = int(pos[0]) + 1  # 1-based\n",
    "                    inv_log = 1.0 / math.log2(rank1 + 1)\n",
    "                    inv_rank = 1.0 / rank1\n",
    "                    for K in K_list:\n",
    "                        if rank1 <= K:\n",
    "                            d = metrics[a][K]\n",
    "                            d[\"hits\"] += 1\n",
    "                            d[\"mrr\"]  += inv_rank\n",
    "                            d[\"ndcg\"] += inv_log\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "# ---------- In kết quả ----------\n",
    "print(f\"\\n[INFO] Tổng mẫu đánh giá: {total}  |  Rows đã dùng: {row_idx}/{num_rows}\")\n",
    "for a in alphas:\n",
    "    for K in K_list:\n",
    "        d = metrics[a][K]\n",
    "        hit = d[\"hits\"]; mrr_sum = d[\"mrr\"]; ndcg_sum = d[\"ndcg\"]\n",
    "        recall = hit / total if total else 0.0                 # LS: Hit@K == Recall@K\n",
    "        precision = hit / (total * K) if total else 0.0        # LS precision\n",
    "        mrr = mrr_sum / total if total else 0.0\n",
    "        ndcg = ndcg_sum / total if total else 0.0\n",
    "        print(f\"[alpha={a:.1f} | K={K:>2}] \"\n",
    "              f\"Recall={recall:.5f}  Precision={precision:.5f}  NDCG={ndcg:.5f}  MRR={mrr:.5f}\")\n",
    "\n",
    "if row_idx != num_rows:\n",
    "    print(f\"[WARN] Số hàng KG không khớp: đã dùng {row_idx}, còn dư {num_rows - row_idx}. \"\n",
    "          \"Đảm bảo thứ tự duyệt khi build kg_matrix khớp test_loader.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9038c7",
   "metadata": {},
   "source": [
    "# LastFM_1B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32da31",
   "metadata": {},
   "source": [
    "## SASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sasrec_config, sasrec_model, sasrec_dataset, sasrec_train_data, sasrec_valid_data, sasrec_test_data = load_data_and_model(\n",
    "    model_file='SASRec_LastFM_filtered.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = sasrec_config['device']\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    sasrec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in sasrec_test_data:\n",
    "        scores = sasrec_model.full_sort_predict(batch[0].to(device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e34bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"KGIN_LastFM_filtered.pth\"\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "cfg = ckpt.get('config', {})\n",
    "cfg['data_path'] = \"./datasets/LastFM_filtered\"     # PATH mới trên máy bạn\n",
    "cfg['dataset']  = \"LastFM_filtered\"                   # phải khớp prefix file dữ liệu\n",
    "\n",
    "ckpt['config'] = cfg\n",
    "fixed_path = \"D:\\Personal\\RecBole\\KGIN_LastFM_filtered_fixed.pth\"\n",
    "torch.save(ckpt, fixed_path)\n",
    "print('Saved:', fixed_path)\n",
    "\n",
    "kgin_config, kgin_model, kgin_dataset, kgin_train_data, kgin_valid_data, kgin_test_data = load_data_and_model(\n",
    "    model_file='KGIN_LastFM_filtered_fixed.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3287c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "def build_kg_matrix_in_ram(\n",
    "    sasrec_dataset, sasrec_test_data,\n",
    "    kg_dataset, kg_model,\n",
    "    dtype=np.float32,           # đổi sang np.float16 nếu cần tiết kiệm RAM\n",
    "    show_progress=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Trả về:\n",
    "      - kg_matrix: np.ndarray shape [num_rows, n_items_seq], dtype=dtype\n",
    "      - row_uid_tokens: list[str] thứ tự user_token tương ứng từng hàng\n",
    "      - seq_pos: np.ndarray[int64] các cột SEQ có tương ứng trong KG\n",
    "      - kg_ids : np.ndarray[int64] id item tương ứng bên KG (cùng chiều với seq_pos)\n",
    "    \"\"\"\n",
    "\n",
    "    kg_model.eval()\n",
    "    kg_device = next(kg_model.parameters()).device\n",
    "\n",
    "    # === Không gian item SEQ và map sang KG ===\n",
    "    n_items_seq = sasrec_dataset.item_num\n",
    "    seq_tokens = [sasrec_dataset.id2token('item_id', i) for i in range(n_items_seq)]\n",
    "    kg_tok2id_item = kg_dataset.field2token_id['item_id']  # token->id (KG)\n",
    "    kg_idx_for_seq = np.array([kg_tok2id_item.get(t, -1) for t in seq_tokens], dtype=np.int64)\n",
    "\n",
    "    # Giới hạn theo kích thước embedding hiện có của KG (an toàn CUDA)\n",
    "    ue = getattr(kg_model, \"user_embedding\", None) or getattr(kg_model, \"entity_embedding\", None)\n",
    "    ie = getattr(kg_model, \"item_embedding\", None) or getattr(kg_model, \"relation_embedding\", None)\n",
    "    MAX_U = None if ue is None else ue.num_embeddings\n",
    "    MAX_I = None if ie is None else ie.num_embeddings\n",
    "\n",
    "    valid_mask = kg_idx_for_seq >= 0\n",
    "    if MAX_I is not None:\n",
    "        valid_mask &= (kg_idx_for_seq < MAX_I)\n",
    "\n",
    "    seq_pos = np.flatnonzero(valid_mask)     # cột trong SEQ có tương ứng ở KG\n",
    "    kg_ids  = kg_idx_for_seq[seq_pos]        # item_id tương ứng bên KG\n",
    "\n",
    "    if len(seq_pos) == 0:\n",
    "        raise RuntimeError(\"Không có item chung hợp lệ giữa SEQ và KG (seq_pos rỗng).\")\n",
    "\n",
    "    # ====== Duyệt test loader & ghép thành ma trận trong RAM ======\n",
    "    rows = []\n",
    "    row_uid_tokens = []\n",
    "\n",
    "    it = tqdm(sasrec_test_data, desc=\"KG → RAM (per-row)\", disable=not show_progress)\n",
    "    with torch.no_grad():\n",
    "        for batch in it:\n",
    "            inp = batch[0]\n",
    "            user_ids   = inp['user_id'].cpu().tolist()\n",
    "            item_lists = inp['item_id_list'].cpu().tolist()   # index theo SEQ\n",
    "\n",
    "            for i, uid in enumerate(user_ids):\n",
    "                # Hàng kết quả (không gian SEQ), mặc định 0.0 cho item không có trong KG\n",
    "                row = np.zeros(n_items_seq, dtype=dtype)\n",
    "\n",
    "                uid_tok = sasrec_dataset.id2token('user_id', uid)\n",
    "                row_uid_tokens.append(uid_tok)\n",
    "\n",
    "                # Tính điểm KG chỉ trên item chung\n",
    "                sub = None\n",
    "                if (uid_tok in kg_dataset.field2token_id['user_id']) and (len(seq_pos) > 0):\n",
    "                    kg_uid = kg_dataset.token2id('user_id', uid_tok)\n",
    "                    if (MAX_U is None) or (kg_uid < MAX_U):\n",
    "                        inter = Interaction({\n",
    "                            'user_id': torch.full((len(kg_ids),), kg_uid, dtype=torch.long),\n",
    "                            'item_id': torch.as_tensor(kg_ids, dtype=torch.long),\n",
    "                        }).to(kg_device)\n",
    "\n",
    "                        try:\n",
    "                            out = kg_model.predict(inter)\n",
    "                        except AttributeError:\n",
    "                            out = kg_model.forward(inter)\n",
    "\n",
    "                        sub = out.detach().cpu().numpy().reshape(-1).astype(dtype)  # len == len(kg_ids)\n",
    "                        row[seq_pos] = sub\n",
    "\n",
    "                # Gán min-score cho item đã tương tác (index theo SEQ), loại pad=0 nếu có\n",
    "                if sub is not None and sub.size > 0:\n",
    "                    min_score = dtype(sub.min())\n",
    "                else:\n",
    "                    min_score = dtype(0.0)\n",
    "\n",
    "                seen_idx = np.fromiter((x for x in set(item_lists[i]) if 0 < x < n_items_seq), dtype=np.int64)\n",
    "                if seen_idx.size > 0:\n",
    "                    row[seen_idx] = min_score\n",
    "\n",
    "                rows.append(row)\n",
    "\n",
    "    # Ghép tất cả hàng thành 1 ma trận trong RAM\n",
    "    kg_matrix = np.stack(rows, axis=0)\n",
    "    return kg_matrix, row_uid_tokens, seq_pos, kg_ids\n",
    "\n",
    "# ==== Ví dụ gọi hàm (giữ trong RAM) ====\n",
    "# CẢNH BÁO RAM: cân nhắc đổi dtype=np.float16 nếu n_items_seq lớn\n",
    "kg_matrix, row_uid_tokens, SEQ_POS, KG_IDS = build_kg_matrix_in_ram(\n",
    "    sasrec_dataset, sasrec_test_data,\n",
    "    kgin_dataset, kgin_model,\n",
    "    dtype=np.float32,     # đổi np.float16 nếu thiếu RAM\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(\"[INFO] KG matrix in RAM:\", kg_matrix.shape, kg_matrix.dtype)\n",
    "print(\"[INFO] Rows (users/sequences):\", len(row_uid_tokens))\n",
    "print(\"[INFO] Common items:\", len(SEQ_POS), \" / SEQ items:\", sasrec_dataset.item_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0059d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, math\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "# ---------- Softmax normalize ----------\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n",
    "\n",
    "# ---------- Cấu hình ----------\n",
    "assert 'kg_matrix' in globals(), \"Thiếu biến kg_matrix (điểm KG trong RAM).\"\n",
    "sasrec_model.eval()\n",
    "device = sasrec_config['device']\n",
    "\n",
    "# K và alpha bạn đang dùng\n",
    "K_list  = [10]\n",
    "alphas  = [round(a, 1) for a in np.arange(0.0, 1.0, 0.1)]\n",
    "maxK = max(K_list)\n",
    "\n",
    "# Hình dạng ma trận KG (phải khớp số cột với không gian item của SEQ)\n",
    "num_rows, n_items_seq = kg_matrix.shape\n",
    "if kg_matrix.dtype != np.float32:\n",
    "    kg_matrix = kg_matrix.astype(np.float32, copy=False)  # đảm bảo float32 (nhanh & gọn)\n",
    "\n",
    "# ---------- Bộ đếm metric (LS) ----------\n",
    "total = 0\n",
    "metrics = {a: {k: {\"hits\": 0, \"mrr\": 0.0, \"ndcg\": 0.0} for k in K_list} for a in alphas}\n",
    "row_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sasrec_test_data, desc=\"Fusion (RAM) + Evaluate\"):\n",
    "        # --- Ground truth (LS) an toàn ---\n",
    "        b1 = batch[1] if len(batch) > 1 else None\n",
    "        if (b1 is not None) and ('item_id' in b1):\n",
    "            gts = b1['item_id'].cpu().tolist()\n",
    "        elif 'item_id' in batch[0]:\n",
    "            # một số cấu hình để GT ở batch[0]\n",
    "            gts = batch[0]['item_id'].cpu().tolist()\n",
    "        else:\n",
    "            # không tìm thấy GT → bỏ qua batch\n",
    "            continue\n",
    "        bsz = len(gts)\n",
    "\n",
    "        # --- Interaction tối thiểu cho SASRec (tránh field thừa) ---\n",
    "        fields = {\n",
    "            'user_id': batch[0]['user_id'],\n",
    "            'item_id_list': batch[0]['item_id_list']\n",
    "        }\n",
    "        if 'item_length' in batch[0]:\n",
    "            fields['item_length'] = batch[0]['item_length']\n",
    "        inter_seq = Interaction({k: v.clone() for k, v in fields.items()})\n",
    "\n",
    "        # --- Seq scores theo batch (GPU→CPU fallback nếu cần) ---\n",
    "        try:\n",
    "            s_scores = sasrec_model.full_sort_predict(inter_seq.to(device)).detach().cpu().numpy()\n",
    "        except RuntimeError as e:\n",
    "            print(\"[WARN] full_sort_predict(GPU) fail, fallback CPU:\", str(e)[:120])\n",
    "            m_cpu = sasrec_model.to('cpu')\n",
    "            s_scores = m_cpu.full_sort_predict(inter_seq.to('cpu')).detach().cpu().numpy()\n",
    "            sasrec_model.to(device)\n",
    "\n",
    "        # --- Bảo đảm còn đủ hàng KG để so khớp ---\n",
    "        if row_idx + bsz > num_rows:\n",
    "            # cắt cho vừa (tránh out-of-range); in cảnh báo\n",
    "            usable = num_rows - row_idx\n",
    "            if usable <= 0:\n",
    "                break\n",
    "            print(f\"[WARN] Cắt batch cuối: cần {bsz}, chỉ còn {usable} hàng KG.\")\n",
    "            gts = gts[:usable]\n",
    "            s_scores = s_scores[:usable]\n",
    "            bsz = usable\n",
    "\n",
    "        # --- Xử lý từng hàng ---\n",
    "        for b in range(bsz):\n",
    "            s_norm = softmax_np(s_scores[b])\n",
    "            k_norm = softmax_np(kg_matrix[row_idx])\n",
    "            gt = gts[b]\n",
    "            total += 1\n",
    "\n",
    "            for a in alphas:\n",
    "                fused = (1.0 - a) * s_norm + a * k_norm\n",
    "\n",
    "                # Top-maxK (argpartition) rồi sort trong top\n",
    "                idx_part = np.argpartition(-fused, maxK - 1)[:maxK]\n",
    "                idx_sorted = idx_part[np.argsort(-fused[idx_part])]\n",
    "\n",
    "                # vị trí GT trong top-maxK (nếu có)\n",
    "                pos = np.where(idx_sorted == gt)[0]\n",
    "                if pos.size > 0:\n",
    "                    rank1 = int(pos[0]) + 1  # 1-based\n",
    "                    inv_log = 1.0 / math.log2(rank1 + 1)\n",
    "                    inv_rank = 1.0 / rank1\n",
    "                    for K in K_list:\n",
    "                        if rank1 <= K:\n",
    "                            d = metrics[a][K]\n",
    "                            d[\"hits\"] += 1\n",
    "                            d[\"mrr\"]  += inv_rank\n",
    "                            d[\"ndcg\"] += inv_log\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "# ---------- In kết quả ----------\n",
    "print(f\"\\n[INFO] Tổng mẫu đánh giá: {total}  |  Rows đã dùng: {row_idx}/{num_rows}\")\n",
    "for a in alphas:\n",
    "    for K in K_list:\n",
    "        d = metrics[a][K]\n",
    "        hit = d[\"hits\"]; mrr_sum = d[\"mrr\"]; ndcg_sum = d[\"ndcg\"]\n",
    "        recall = hit / total if total else 0.0                 # LS: Hit@K == Recall@K\n",
    "        precision = hit / (total * K) if total else 0.0        # LS precision\n",
    "        mrr = mrr_sum / total if total else 0.0\n",
    "        ndcg = ndcg_sum / total if total else 0.0\n",
    "        print(f\"[alpha={a:.1f} | K={K:>2}] \"\n",
    "              f\"Recall={recall:.5f}  Precision={precision:.5f}  NDCG={ndcg:.5f}  MRR={mrr:.5f}\")\n",
    "\n",
    "if row_idx != num_rows:\n",
    "    print(f\"[WARN] Số hàng KG không khớp: đã dùng {row_idx}, còn dư {num_rows - row_idx}. \"\n",
    "          \"Đảm bảo thứ tự duyệt khi build kg_matrix khớp test_loader.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce368b3",
   "metadata": {},
   "source": [
    "## BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbad2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"BERT4Rec_LastFM_filtered.pth\"\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "cfg = ckpt.get('config', {})\n",
    "cfg['data_path'] = \"./datasets/LastFM_filtered\"     # PATH mới trên máy bạn\n",
    "cfg['dataset']  = \"LastFM_filtered\"                   # phải khớp prefix file dữ liệu\n",
    "\n",
    "ckpt['config'] = cfg\n",
    "fixed_path = \"D:\\Personal\\RecBole\\BERT4Rec_LastFM_filtered_fixed.pth\"\n",
    "torch.save(ckpt, fixed_path)\n",
    "print('Saved:', fixed_path)\n",
    "\n",
    "bert4rec_config, bert4rec_model, bert4rec_dataset, bert4rec_train_data, bert4rec_valid_data, bert4rec_test_data = load_data_and_model(\n",
    "    model_file='BERT4Rec_LastFM_filtered_fixed.pth'\n",
    ")\n",
    "\n",
    "device = bert4rec_config['device']\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    bert4rec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in bert4rec_test_data:\n",
    "        scores = bert4rec_model.full_sort_predict(batch[0].to(device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, math\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n",
    "\n",
    "assert 'kg_matrix' in globals(), \"Thiếu biến kg_matrix (điểm KG trong RAM).\"\n",
    "bert4rec_model.eval()\n",
    "device = bert4rec_config['device']\n",
    "\n",
    "K_list  = [10]\n",
    "alphas  = [round(a, 1) for a in np.arange(0.0, 1.0, 0.1)]\n",
    "maxK = max(K_list)\n",
    "\n",
    "num_rows, n_items_seq = kg_matrix.shape\n",
    "if kg_matrix.dtype != np.float32:\n",
    "    kg_matrix = kg_matrix.astype(np.float32, copy=False)  \n",
    "\n",
    "total = 0\n",
    "metrics = {a: {k: {\"hits\": 0, \"mrr\": 0.0, \"ndcg\": 0.0} for k in K_list} for a in alphas}\n",
    "row_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sasrec_test_data, desc=\"Fusion (RAM) + Evaluate\"):\n",
    "        # --- Ground truth (LS) an toàn ---\n",
    "        b1 = batch[1] if len(batch) > 1 else None\n",
    "        if (b1 is not None) and ('item_id' in b1):\n",
    "            gts = b1['item_id'].cpu().tolist()\n",
    "        elif 'item_id' in batch[0]:\n",
    "            # một số cấu hình để GT ở batch[0]\n",
    "            gts = batch[0]['item_id'].cpu().tolist()\n",
    "        else:\n",
    "            # không tìm thấy GT → bỏ qua batch\n",
    "            continue\n",
    "        bsz = len(gts)\n",
    "\n",
    "        # --- Interaction tối thiểu cho SASRec (tránh field thừa) ---\n",
    "        fields = {\n",
    "            'user_id': batch[0]['user_id'],\n",
    "            'item_id_list': batch[0]['item_id_list']\n",
    "        }\n",
    "        if 'item_length' in batch[0]:\n",
    "            fields['item_length'] = batch[0]['item_length']\n",
    "        inter_seq = Interaction({k: v.clone() for k, v in fields.items()})\n",
    "\n",
    "        # --- Seq scores theo batch (GPU→CPU fallback nếu cần) ---\n",
    "        try:\n",
    "            s_scores = bert4rec_model.full_sort_predict(inter_seq.to(device)).detach().cpu().numpy()\n",
    "        except RuntimeError as e:\n",
    "            print(\"[WARN] full_sort_predict(GPU) fail, fallback CPU:\", str(e)[:120])\n",
    "            m_cpu = bert4rec_model.to('cpu')\n",
    "            s_scores = m_cpu.full_sort_predict(inter_seq.to('cpu')).detach().cpu().numpy()\n",
    "            bert4rec_model.to(device)\n",
    "\n",
    "        # --- Bảo đảm còn đủ hàng KG để so khớp ---\n",
    "        if row_idx + bsz > num_rows:\n",
    "            # cắt cho vừa (tránh out-of-range); in cảnh báo\n",
    "            usable = num_rows - row_idx\n",
    "            if usable <= 0:\n",
    "                break\n",
    "            print(f\"[WARN] Cắt batch cuối: cần {bsz}, chỉ còn {usable} hàng KG.\")\n",
    "            gts = gts[:usable]\n",
    "            s_scores = s_scores[:usable]\n",
    "            bsz = usable\n",
    "\n",
    "        # --- Xử lý từng hàng ---\n",
    "        for b in range(bsz):\n",
    "            s_norm = softmax_np(s_scores[b])\n",
    "            k_norm = softmax_np(kg_matrix[row_idx])\n",
    "            gt = gts[b]\n",
    "            total += 1\n",
    "\n",
    "            for a in alphas:\n",
    "                fused = (1.0 - a) * s_norm + a * k_norm\n",
    "\n",
    "                # Top-maxK (argpartition) rồi sort trong top\n",
    "                idx_part = np.argpartition(-fused, maxK - 1)[:maxK]\n",
    "                idx_sorted = idx_part[np.argsort(-fused[idx_part])]\n",
    "\n",
    "                # vị trí GT trong top-maxK (nếu có)\n",
    "                pos = np.where(idx_sorted == gt)[0]\n",
    "                if pos.size > 0:\n",
    "                    rank1 = int(pos[0]) + 1  # 1-based\n",
    "                    inv_log = 1.0 / math.log2(rank1 + 1)\n",
    "                    inv_rank = 1.0 / rank1\n",
    "                    for K in K_list:\n",
    "                        if rank1 <= K:\n",
    "                            d = metrics[a][K]\n",
    "                            d[\"hits\"] += 1\n",
    "                            d[\"mrr\"]  += inv_rank\n",
    "                            d[\"ndcg\"] += inv_log\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "# ---------- In kết quả ----------\n",
    "print(f\"\\n[INFO] Tổng mẫu đánh giá: {total}  |  Rows đã dùng: {row_idx}/{num_rows}\")\n",
    "for a in alphas:\n",
    "    for K in K_list:\n",
    "        d = metrics[a][K]\n",
    "        hit = d[\"hits\"]; mrr_sum = d[\"mrr\"]; ndcg_sum = d[\"ndcg\"]\n",
    "        recall = hit / total if total else 0.0                 # LS: Hit@K == Recall@K\n",
    "        precision = hit / (total * K) if total else 0.0        # LS precision\n",
    "        mrr = mrr_sum / total if total else 0.0\n",
    "        ndcg = ndcg_sum / total if total else 0.0\n",
    "        print(f\"[alpha={a:.1f} | K={K:>2}] \"\n",
    "              f\"Recall={recall:.5f}  Precision={precision:.5f}  NDCG={ndcg:.5f}  MRR={mrr:.5f}\")\n",
    "\n",
    "if row_idx != num_rows:\n",
    "    print(f\"[WARN] Số hàng KG không khớp: đã dùng {row_idx}, còn dư {num_rows - row_idx}. \"\n",
    "          \"Đảm bảo thứ tự duyệt khi build kg_matrix khớp test_loader.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9834b",
   "metadata": {},
   "source": [
    "## FEARec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09154012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"FEARec_LastFM_filtered.pth\"\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "cfg = ckpt.get('config', {})\n",
    "cfg['data_path'] = \"./datasets/LastFM_filtered\"     # PATH mới trên máy bạn\n",
    "cfg['dataset']  = \"LastFM_filtered\"                   # phải khớp prefix file dữ liệu\n",
    "\n",
    "ckpt['config'] = cfg\n",
    "fixed_path = \"D:\\Personal\\RecBole\\FEA4Rec_LastFM_filtered_fixed.pth\"\n",
    "torch.save(ckpt, fixed_path)\n",
    "print('Saved:', fixed_path)\n",
    "\n",
    "fearec_config, fearec_model, fearec_dataset, fearec_train_data, fearec_valid_data, fearec_test_data = load_data_and_model(\n",
    "    model_file='FEA4Rec_LastFM_filtered_fixed.pth'\n",
    ")\n",
    "\n",
    "device = fearec_config['device']\n",
    "\n",
    "# evaluate seq_model\n",
    "for k in [5, 10, 20, 50]:\n",
    "    fearec_model.eval()\n",
    "    all_ranks = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for batch in fearec_test_data:\n",
    "        scores = fearec_model.full_sort_predict(batch[0].to(device))\n",
    "\n",
    "        # Get top-K predicted items\n",
    "        topk = scores.topk(k=k, dim=-1).indices\n",
    "        all_ranks.append(topk.cpu())\n",
    "\n",
    "        # Ground truth\n",
    "        ground_truth = batch[0]['item_id']\n",
    "        all_ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "    topk_items = torch.cat(all_ranks, dim=0).tolist()\n",
    "    true_items = torch.cat(all_ground_truths, dim=0).tolist()\n",
    "\n",
    "    recall = recall_at_k(topk_items, true_items, k=k)\n",
    "    ndcg = mean_ndcg_at_k_ls(topk_items, true_items, k=k)\n",
    "    mrr = mrr_at_k(topk_items, true_items, k=k)\n",
    "    precision = precision_at_k(topk_items, true_items, k=k)\n",
    "\n",
    "    print(f'Recall@{k}: {recall:.4f}, NDCG@{k}: {ndcg:.4f}, MRR@{k}: {mrr:.4f}, precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, math\n",
    "from tqdm import tqdm\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "# ---------- Softmax normalize ----------\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    m = np.max(x)\n",
    "    e = np.exp(x - m)\n",
    "    s = e.sum()\n",
    "    if s == 0:\n",
    "        return np.full_like(x, 1.0 / len(x))\n",
    "    return e / s\n",
    "\n",
    "# ---------- Cấu hình ----------\n",
    "assert 'kg_matrix' in globals(), \"Thiếu biến kg_matrix (điểm KG trong RAM).\"\n",
    "fearec_model.eval()\n",
    "device = fearec_config['device']\n",
    "\n",
    "# K và alpha bạn đang dùng\n",
    "K_list  = [10]\n",
    "alphas  = [round(a, 1) for a in np.arange(0.0, 1.0, 0.1)]\n",
    "maxK = max(K_list)\n",
    "\n",
    "# Hình dạng ma trận KG (phải khớp số cột với không gian item của SEQ)\n",
    "num_rows, n_items_seq = kg_matrix.shape\n",
    "if kg_matrix.dtype != np.float32:\n",
    "    kg_matrix = kg_matrix.astype(np.float32, copy=False)  # đảm bảo float32 (nhanh & gọn)\n",
    "\n",
    "# ---------- Bộ đếm metric (LS) ----------\n",
    "total = 0\n",
    "metrics = {a: {k: {\"hits\": 0, \"mrr\": 0.0, \"ndcg\": 0.0} for k in K_list} for a in alphas}\n",
    "row_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sasrec_test_data, desc=\"Fusion (RAM) + Evaluate\"):\n",
    "        # --- Ground truth (LS) an toàn ---\n",
    "        b1 = batch[1] if len(batch) > 1 else None\n",
    "        if (b1 is not None) and ('item_id' in b1):\n",
    "            gts = b1['item_id'].cpu().tolist()\n",
    "        elif 'item_id' in batch[0]:\n",
    "            # một số cấu hình để GT ở batch[0]\n",
    "            gts = batch[0]['item_id'].cpu().tolist()\n",
    "        else:\n",
    "            # không tìm thấy GT → bỏ qua batch\n",
    "            continue\n",
    "        bsz = len(gts)\n",
    "\n",
    "        # --- Interaction tối thiểu cho SASRec (tránh field thừa) ---\n",
    "        fields = {\n",
    "            'user_id': batch[0]['user_id'],\n",
    "            'item_id_list': batch[0]['item_id_list']\n",
    "        }\n",
    "        if 'item_length' in batch[0]:\n",
    "            fields['item_length'] = batch[0]['item_length']\n",
    "        inter_seq = Interaction({k: v.clone() for k, v in fields.items()})\n",
    "\n",
    "        # --- Seq scores theo batch (GPU→CPU fallback nếu cần) ---\n",
    "        try:\n",
    "            s_scores = fearec_model.full_sort_predict(inter_seq.to(device)).detach().cpu().numpy()\n",
    "        except RuntimeError as e:\n",
    "            print(\"[WARN] full_sort_predict(GPU) fail, fallback CPU:\", str(e)[:120])\n",
    "            m_cpu = fearec_model.to('cpu')\n",
    "            s_scores = m_cpu.full_sort_predict(inter_seq.to('cpu')).detach().cpu().numpy()\n",
    "            fearec_model.to(device)\n",
    "\n",
    "        # --- Bảo đảm còn đủ hàng KG để so khớp ---\n",
    "        if row_idx + bsz > num_rows:\n",
    "            # cắt cho vừa (tránh out-of-range); in cảnh báo\n",
    "            usable = num_rows - row_idx\n",
    "            if usable <= 0:\n",
    "                break\n",
    "            print(f\"[WARN] Cắt batch cuối: cần {bsz}, chỉ còn {usable} hàng KG.\")\n",
    "            gts = gts[:usable]\n",
    "            s_scores = s_scores[:usable]\n",
    "            bsz = usable\n",
    "\n",
    "        # --- Xử lý từng hàng ---\n",
    "        for b in range(bsz):\n",
    "            s_norm = softmax_np(s_scores[b])\n",
    "            k_norm = softmax_np(kg_matrix[row_idx])\n",
    "            gt = gts[b]\n",
    "            total += 1\n",
    "\n",
    "            for a in alphas:\n",
    "                fused = (1.0 - a) * s_norm + a * k_norm\n",
    "\n",
    "                # Top-maxK (argpartition) rồi sort trong top\n",
    "                idx_part = np.argpartition(-fused, maxK - 1)[:maxK]\n",
    "                idx_sorted = idx_part[np.argsort(-fused[idx_part])]\n",
    "\n",
    "                # vị trí GT trong top-maxK (nếu có)\n",
    "                pos = np.where(idx_sorted == gt)[0]\n",
    "                if pos.size > 0:\n",
    "                    rank1 = int(pos[0]) + 1  # 1-based\n",
    "                    inv_log = 1.0 / math.log2(rank1 + 1)\n",
    "                    inv_rank = 1.0 / rank1\n",
    "                    for K in K_list:\n",
    "                        if rank1 <= K:\n",
    "                            d = metrics[a][K]\n",
    "                            d[\"hits\"] += 1\n",
    "                            d[\"mrr\"]  += inv_rank\n",
    "                            d[\"ndcg\"] += inv_log\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "# ---------- In kết quả ----------\n",
    "print(f\"\\n[INFO] Tổng mẫu đánh giá: {total}  |  Rows đã dùng: {row_idx}/{num_rows}\")\n",
    "for a in alphas:\n",
    "    for K in K_list:\n",
    "        d = metrics[a][K]\n",
    "        hit = d[\"hits\"]; mrr_sum = d[\"mrr\"]; ndcg_sum = d[\"ndcg\"]\n",
    "        recall = hit / total if total else 0.0                 # LS: Hit@K == Recall@K\n",
    "        precision = hit / (total * K) if total else 0.0        # LS precision\n",
    "        mrr = mrr_sum / total if total else 0.0\n",
    "        ndcg = ndcg_sum / total if total else 0.0\n",
    "        print(f\"[alpha={a:.1f} | K={K:>2}] \"\n",
    "              f\"Recall={recall:.5f}  Precision={precision:.5f}  NDCG={ndcg:.5f}  MRR={mrr:.5f}\")\n",
    "\n",
    "if row_idx != num_rows:\n",
    "    print(f\"[WARN] Số hàng KG không khớp: đã dùng {row_idx}, còn dư {num_rows - row_idx}. \"\n",
    "          \"Đảm bảo thứ tự duyệt khi build kg_matrix khớp test_loader.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
